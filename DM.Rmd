---
author : "Khalil Janbek, Romain Jouhameau"
date: "01/01/2022"
output:
  pdf_document: 
  html_document:
    df_print: paged
editor_options: 
  markdown: 
    wrap: 72
    
header-includes:
  \usepackage[english]{babel}
  \usepackage[T1]{fontenc}
  \usepackage{tgbonum}
  \usepackage{multicol,multirow}
  \usepackage{calc}
  \usepackage{graphicx}
  \usepackage{rotating}
  \usepackage{tgtermes} 
  \usepackage{fancyhdr} 
  \usepackage{float} 
  \usepackage{xcolor} 
  \usepackage{geometry} 
  \usepackage{amsfonts} 
  \usepackage{booktabs}
  \usepackage{siunitx}
  \newcolumntype{d}{S[input-symbols = ()]}
  
  \geometry{left=0.8in,right=0.8in,top=1.0in,bottom=1.0in}
  \setlength{\parindent}{1.25em}
  \setlength{\parskip}{0.1em}
  
  \title{Applied Econometrics Homework \\ M2 FE }
---

```{=tex}
\pagestyle{fancy}
\fancyhf{}
\rhead{Khalil Janbek, Jouhameau Romain}
\lhead{Applied Econometrics Homework}
\rfoot{Page \thepage}
\maketitle
```
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                      message=FALSE, 
                      warning=FALSE,  
                      results = "hold",
                      out.width = '70%',
                      fig.align='center',
                      comment = "#>")
```

```{r}
library(data.table)
library(dtplyr)
library(dplyr, warn.conflicts = FALSE)
library(readxl)
library(janitor)
library(plm)
library(modelsummary)
library(kableExtra)
library(ggrepel) # for spacing text inside plots
library(tidyverse)
library(sf)
library(usmap)
library(tsibble)
library(DBI) 
library(DataExplorer)

```

```{r}
con <- dbConnect(RSQLite::SQLite(), "Data/DB.sqlite")
DB = tbl(con, "DB")

DB %>% 
  head() %>% 
  collect()
```



\newpage

## PART A:

Option 1 - Master thesis dataset

Khalil's Master thesis explores the topic of the performance of securitized mortgage loans in the US in the context of the coronavirus crisis. Based on issuance and performance data for more than 346,724 mortgage loans purchased by Freddie Mac in 2020Q1, combined with neighborhood-level coronavirus data, the thesis will examine, at the US local level, whether the coronavirus outbreak affected these loans' (i) delinquency status and (ii) prepayment. In parallel, the Master thesis also enquires whether the status of the lender that originated the loan - commercial bank or shadow bank, Fintech or not - has an influence on those two loan performance metrics. 

\newpage


#### 1. In your data set, which are the variables which are varying with respect to two indices (or more if you consider inflows and outflows from one individual or country to another individual or countries? Which are the variables which are varying only with respect to time? Which are the variables which are varying only with respect to individuals?

For each loan, the database records: 

- (i) time-invariant issuance metrics. Those variables vary only  with respect to individuals (in other words by loan) and do not vary over. Those time-invariant variables regroup for instance borrower credit score at issuance, the original loan to value, XXX and the lender type. 

- (ii) time-varying performance metrics. Those variables vary both with respect to time and with respect to individuals. For instance, prepayment (Zero Balance Code), Delinquency status, and unpaid principal. 



#### 2. What is the largest number of period T for individuals? What is the number of individuals?


The dataset counts 17 time periods, spanning from a month in 2020Q1 to June 2021. The sample consists of 346,724 loans, originated at various dates but purchased by Freddie Mac in 2020Q1. 

```{r}
DB %>% 
  count(Loan_Seq_Number) %>% 
  summarise(Number_Loans = n(),
            Max_T = max(n, na.rm = TRUE),
            Min_T = min(n, na.rm = TRUE),
            Mean_T = mean(n, na.rm = TRUE),
            Median_T = median(n, na.rm = TRUE),
            ) %>% 
  collect()
```
Lenders originating and selling these mortgage loans are classified as either commercial banks or shadow banks. The latter category also includes Fintech lenders. 

```{r}
DB %>%  
  mutate(Type = case_when(
           Lender_Type == 1 ~ 'Bank',
           Lender_Type == 0 & Fintech == 0 ~ 'Shadow Bank',
           Lender_Type == 0 & Fintech == 1 ~ 'Fintech'
         )) %>% 
  group_by(Type) %>% 
  count(Loan_Seq_Number) %>% 
  summarise(Number_Loans = n(),
                   Max_T = max(n, na.rm = TRUE),
                   Min_T = min(n, na.rm = TRUE),
                   Mean_T = mean(n, na.rm = TRUE),
                   Median_T = median(n, na.rm = TRUE)) %>% 
  collect()
```

\newpage



#### 3. Comment on the structure of the unbalanced panel (how many (and which) countries have a single observation, discontinuities between observations, how many have at least 2 consecutive observations (which is useful to compute lags, autocorrelations, first difference and within estimators)?

As shown in the previous question, our dataset has an unbalanced panel data structure, with time periods per individual loan varying from 1 to 17.


\newpage

```{r}
DB_temp <- DB %>% 
  # Reformatting the "Zero Balance Code" variable: 1 if prepaid, 0 otherwise
  mutate(Zero_Balance_Code = ifelse(Zero_Balance_Code == 1, 1, 0),
         Zero_Balance_Code = ifelse(is.na(Zero_Balance_Code) == T, 0, Zero_Balance_Code)) %>% 
  # Reformatting the "Delinquency status" variable: counting "REO acquisition as "NA"
  mutate(Delinquency_Status = ifelse(Delinquency_Status == 'RA', NA, Delinquency_Status)) %>% 
  # Reformatting the "Estimated Loan-to-Value" variable: counting "999" as "NA"
  mutate(E_LoanToValue = ifelse(E_LoanToValue == 999, NA, E_LoanToValue)) %>% 
  # Reformatting the "Original Debt-to-Income" variable: counting "999" as "NA"
  mutate(O_DebtToIncome = ifelse(O_DebtToIncome == 999, NA, O_DebtToIncome)) 
```


```{r}
DB_KJ <- DB_temp %>% 
  select(Loan_Seq_Number, Reporting_Period, Delinquency_Status, Zero_Balance_Code,
         confirmed, Credit_score, Current_Interest_Rate,Current_UPB, E_LoanToValue,
         O_DebtToIncome, Time_to_Maturity, Lender_Type, Fintech, MSA, Seller_Name) %>% 
  mutate(Delinquency_Status = as.integer(Delinquency_Status)) %>% 
  collect() %>% 
  #mutate(Reporting_Period = lubridate::ymd(Reporting_Period)) %>% 
  mutate_if(is.integer, as.double)
```


```{r}
Loans_by_MSA <- 
  DB %>%                             
  group_by(MSA) %>%
  summarise(LoansPerMSA = n_distinct(Loan_Seq_Number)) %>% 
  collect()

Loans_by_MSA

# Identifying which loans are not related to an MSA (22,351 / 346,724)
#sum(Loans_by_MSA$LoansPerMSA)
```





```{r}
DB %>%
  group_by(Loan_Seq_Number) %>%
  tally() %>% 
  count(n) %>%
  rename(Number_Periods_available = n,
         Number_of_loans = nn) %>% 
  mutate(cum = cumsum(Number_of_loans),
         percent = 100 * (cum / 346724))
```



```{r}
# Between transformation
between_transformation <- 
  lazy_dt(DB_KJ[c(1:10000),]) %>% 
  group_by(Loan_Seq_Number) %>% 
  summarise_if(is.double, mean, na.rm = T) %>% 
  collect()
```

```{r}
fatal_fe_mod <- plm(Current_UPB ~ E_LoanToValue, 
                    data = DB_KJ[c(1:10000),],
                    index = c("Loan_Seq_Number", "Reporting_Period"), 
                    model = "between")

summary(fatal_fe_mod)
```

```{r}
between_transformation %>% lm(Current_UPB ~ E_LoanToValue, data = .)
```





```{r}
# Within transformation
lazy_dt(DB_KJ) %>% 
  group_by(Loan_Seq_Number) %>% 
  mutate_at(vars(Delinquency_Status:Fintech), ~ . -  mean(., na.rm = T)) %>% 
  collect()
```


```{r}

between(Panel_DB_KJ$E_LoanToValue, effect = c("individual", "time", "group")) %>% 
  tibble()
```


```{r}
Delinquency_Status <- Panel_DB_KJ$Delinquency_Status
Current_Interest_Rate <- Panel_DB_KJ$Current_Interest_Rate
E_LoanToValue <- Panel_DB_KJ$E_LoanToValue
Credit_score <- Panel_DB_KJ$Credit_score
O_Debt_to_Income <- Panel_DB_KJ$O_Debt_to_Income
Current_UPB <- Panel_DB_KJ$Current_UPB
Time_to_Maturity <- Panel_DB_KJ$Time_to_Maturity
COVID <- Panel_DB_KJ$COVID

as.matrix(Delinquency_Status)
as.matrix(Current_Interest_Rate)
as.matrix(E_LoanToValue)
as.matrix(Credit_score)
as.matrix(O_Debt_to_Income)
as.matrix(Current_UPB)
as.matrix(Time_to_Maturity)
as.matrix(COVID)

?between()

between(Delinquency_Status, effect = c("individual", "time", "group"))
between(Current_Interest_Rate, effect = c("individual", "time", "group"))
between(E_LoanToValue, effect = c("individual", "time", "group"))
between(Credit_score, effect = c("individual", "time", "group"))
between(O_Debt_to_Income, effect = c("individual", "time", "group"))
between(Current_UPB, effect = c("individual", "time", "group"))
between(Time_to_Maturity, effect = c("individual", "time", "group"))
between(COVID, effect = c("individual", "time", "group"))
```



Starting by exploring missing observations, the graph shows that 6.75% of monthly loan performance observations relate to mortgage loans originated in locations that are not in an MSA - amounting to 22,351 loans, or 6.4% of the total of mortgages in our database. Those loans are likely to have been originated in sparsely populated areas.  

Monthly developments in COVID-19 confirmed cases by MSA are also missing in 8.45% of our monthly loan performance observations. This percentage includes the 6.75% of loan performance observations that are not located in an MSA. As our loan performance data start in February 2020, the remaining missing COVID-19 observations are related to monthly loan performance data that date prior to March 2020 - date at which COVID-19 cases started to be tracked. 

```{r}
plot_missing(Final_DB)

Loans_by_MSA <- 
  Final_DB %>%                             
  group_by(MSA) %>%
  summarise(LoansPerMSA = n_distinct(Loan_Seq_Number))

```

As briefly shown in question 2, we have between 1 and 17 consecutive observation for each loan contract. Nonetheless, the number of loans for which we have only 1 period of observation is very small compared to the total number of loans of the dataset - 123 out 346,724, or 0.3%. All the other loans therefore have at least 2 consecutive observations.


```{r}
Final_DB %>%
  group_by(Loan_Seq_Number) %>%
  tally() %>% 
  count(n) %>%
  summarise(Number_Periods_available = n,
            Number_of_loans = nn)
```

None of our loan performance data display discontinuities between observations.   

#### 4. Compute between transformed and within transformed variables for all variables. Present a table with the within, between and pooled variance for each variable. Compute the share of between and within variance in the total variance for each variable. Comment these results.



\newpage


#### 5. Plot the distribution of the within and between transformed dependent variable and of you key (preferred) explanatory variable (not all the explanatory variable) [in Burnside and Dollar: GDP growth and foreign aid EDA/GDP], using on the same graph an histogram, a normal law with same empirical mean and standard error and a kernel continuous approximation. Comment the between and within difference for each variable, and compare within/within for dependent and explanatory variable, and between/between for dependent and explanatory variable: kurtosis, skewness, non-normality, high leverage observation (far from the mean), several modes (mixture of distribution)?

\newpage

Definitions of between and within transformation: XXX

We carry out the calculation of within and between transformations for all variables except the binary variables - namely the lender type - because XXX. 


```{r}
# Between transformation
between_transformation <- panel_data %>% 
  group_by(country) %>% 
  mutate(oda_net_gdp_cap = oda_net / gdp_per_cap) %>% 
  summarise(across(where(is.double), mean, na.rm = T))
```


```{r}
between(Delinquency_Status, effect = c("individual", "time", "group"))
between(Current_Interest_Rate, effect = c("individual", "time", "group"))
between(E_LoanToValue, effect = c("individual", "time", "group"))
between(Credit_score, effect = c("individual", "time", "group"))
between(O_Debt_to_Income, effect = c("individual", "time", "group"))
between(Current_UPB, effect = c("individual", "time", "group"))
between(Time_to_Maturity, effect = c("individual", "time", "group"))
between(COVID, effect = c("individual", "time", "group"))

Between(Delinquency_Status, effect = c("individual", "time", "group"))
Between(Current_Interest_Rate, effect = c("individual", "time", "group"))
Between(E_LoanToValue, effect = c("individual", "time", "group"))
Between(Credit_score, effect = c("individual", "time", "group"))
Between(O_Debt_to_Income, effect = c("individual", "time", "group"))
Between(Current_UPB, effect = c("individual", "time", "group"))
Between(Time_to_Maturity, effect = c("individual", "time", "group"))
Between(COVID, effect = c("individual", "time", "group"))

Within(Delinquency_Status,effect = c("individual", "time", "group"))
Within(Current_Interest_Rate,effect = c("individual", "time", "group"))
Within(E_LoanToValue,effect = c("individual", "time", "group"))
Within(Credit_score,effect = c("individual", "time", "group"))
Within(O_Debt_to_Income,effect = c("individual", "time", "group"))
Within(Current_UPB,effect = c("individual", "time", "group"))
Within(Time_to_Maturity,effect = c("individual", "time", "group"))
Within(COVID,effect = c("individual", "time", "group"))

Sum(Delinquency_Status,effect = c("individual", "time", "group"))
Sum(Current_Interest_Rate,effect = c("individual", "time", "group"))
Sum(E_LoanToValue,effect = c("individual", "time", "group"))
Sum(Credit_score,effect = c("individual", "time", "group"))
Sum(O_Debt_to_Income,effect = c("individual", "time", "group"))
Sum(Current_UPB,effect = c("individual", "time", "group"))
Sum(Time_to_Maturity,effect = c("individual", "time", "group"))
Sum(COVID,effect = c("individual", "time", "group"))

Variance <- Panel_DB_KJ %>%
  dplyr::select(Final_DB.Loan_Seq_Number, Final_DB.Reporting_Period, Delinquency_Status,
                Current_Interest_Rate, E_LoanToValue, Credit_score, O_Debt_to_Income,
                Current_UPB, Time_to_Maturity, COVID) %>%
  gather(variable, value, -Final_DB.Loan_Seq_Number, -Final_DB.Reporting_Period) %>%
  group_by(variable) %>%
  summarize(var = var(value))

Within.Variance <-c('W.Delinquency', 'W.Interest', 'W.ELTV', 'W.Score', 'W.ODTI',
                    'W.CUPB', 'W.TTM', 'W.COVID')
Between.Variance <- c('M.Delinquency', 'M.Interest', 'M.ELTV', 'M.Score', 'M.ODTI',
                      'M.CUPB','M.TTM','M.COVID')

Within.Variance.values  <- Panel_DB_KJ %>%
  dplyr::select(Final_DB.Loan_Seq_Number, Final_DB.Reporting_Period, Within.Variance) %>%
  gather(variable, value, -Final_DB.Loan_Seq_Number, -Final_DB.Reporting_Period) %>%
  group_by(variable) %>%
  summarize(var = var(value))

Between.Variance.values  <- Panel_DB_KJ %>%
  dplyr::select(Final_DB.Loan_Seq_Number, Final_DB.Reporting_Period, Between.Variance) %>%
  gather(variable, value, -Final_DB.Loan_Seq_Number, -Final_DB.Reporting_Period) %>%
  group_by(variable) %>%
  summarize(var = var(value))

Three.variances <- Variance %>% bind_cols(Within.Variance.values, Between.Variance.values) %>%
  dplyr::select(-variable1, -variable2) %>%
  rename(Variable = variable, Overall = var, Within = var1, Between = var2) %>%
  mutate(`Within Variance Share` = (Within/Overall)*100,
         `Between Variance Share` = (Between/Overall)*100) %>%
  na.omit()
Three.variances

```

#### 5. Plot the distribution of the within and between transformed dependent variable and of you key (preferred) explanatory variable (not all the explanatory variable) [in Burnside and Dollar: GDP growth and foreign aid EDA/GDP], using on the same graph an histogram, a normal law with same empirical mean and standard error and a kernel continuous approximation. Comment the between and within difference for each variable, and compare within/within for dependent and explanatory variable, and between/between for dependent and explanatory variable: kurtosis, skewness, non-normality, high leverage observation (far from the mean), several modes (mixture of distribution)?

```{r}
Top100.5. <- Top100.2. %>%
  dplyr::select(Company, Year, M.RNIFA, W.RNIFA, M.RFD, W.RFD) %>%
  na.omit()

#Between Graph RNIFA
Top100.5. %>%
  ggplot(aes(x = M.RNIFA)) +
  geom_histogram(aes(y = ..density..), binwidth = 0.05) +
  geom_density(aes(y = ..density..), colour='red', size = 0.7, linetype = 1, adjust = 2) +
  labs(title="Between Transformed Net Intangible Fixed Assets",
       x = element_blank(), y = "Density")


#Between Graph RFD
Top100.5. %>%
  ggplot(aes(x = M.RFD)) +
  geom_histogram(aes(y = ..density..), binwidth = 0.05) +
  geom_density(aes(y = ..density..), colour='red', size = 0.7, linetype = 1, adjust = 2) +
  labs(title="Between Transformed Financial Debt",
       x = element_blank(), y = "Density")

#Within Graph RNIFA
Top100.5. %>%
  ggplot(aes(x = W.RNIFA)) +
  geom_histogram(aes(y = ..density..), binwidth = 0.05) +
  geom_density(aes(y = ..density..), colour='red', size = 0.7, linetype = 1, adjust = 2) +
  labs(title="Within Transformed Net Intangible Fixed Assets",
       x = element_blank(), y = "Density")

#Within Graph RFD
Top100.5. %>%
  ggplot(aes(x = W.RNIFA)) +
  geom_histogram(aes(y = ..density..), binwidth = 0.05) +
  geom_density(aes(y = ..density..), colour='red', size = 0.7, linetype = 1, adjust = 2) +
  labs(title="Within Transformed Financial Debt",
       x = element_blank(), y = "Density")
```
>>>>>>> 3b08fd179db8a4542130c39ebfef6a47be8ea267


#### 6. Plot boxplot of within distribution and between distribution for the dependent variable and the key explanatory variables. Comment that you find the same insights from question 5.


\newpage

#### 7. Compute univariate descriptive statistics (min, Q1, median, Q3, max, mean, standard error) for Within and Between transformed variables. Is the mean different from the median and why? How many standard errors from the mean are the min and max extremes (report (MAX-average)/standard error and (MIN-average)/standard error in the tables)?

\newpage

#### 8. Plot the boxplot of within transformed dependent variable and the key explanatory variable by a few individual (all of them if N around 50) and only the first 20 of them for larger data set. Comment on their differences of standard errors and means for each individuals

\newpage

#### 9. Compare and comment the within and between transformed bivariate correlation matrix for all variables (include a time trend 1,2,.,T). Check poor simple correlation with the dependent variables and high correlation between explanatory variables.

\newpage


```{r}
boxplot(Top100.5.$M.RNIFA, Top100.5.$M.RFD, Top100.5.$W.RNIFA, Top100.5.$W.RFD,
        main = "Boxplots for comparision",
        at = c(1,2,4,5),
        names = c("Between w", "Between", "Within", "Within"),
        las = 1,
        col = c("orange","red"),
        size = 2,
        border = "brown",
        horizontal = TRUE,
        notch = TRUE)
```


#### 7. Compute univariate descriptive statistics (min, Q1, median, Q3, max, mean, standard error) for Within and Between transformed variables. Is the mean different from the median and why? How many standard errors from the mean are the min and max extremes (report (MAX-average)/standard error and (MIN-average)/standard error in the tables)?

```{r}
#Dependent variable
#Between
mean.M.RNIFA <- mean(Top100.5.$M.RNIFA)
median.M.RNIFA <- median(Top100.5.$M.RNIFA)
range.M.RNIFA <-range(Top100.5.$M.RNIFA)
standard.deviation.M.RNIFA <-sd(Top100.5.$M.RNIFA)
variance.M.RNIFA <-var(Top100.5.$M.RNIFA)

standard.error <- function(x) {
  sqrt(var(x)/length(x))
}
standard.error.M.RNIFA <- standard.error(Top100.5.$M.RNIFA)
skewness.M.RNIFA <-skewness(Top100.5.$M.RNIFA)
kurtosis.M.RNIFA <-kurtosis(Top100.5.$M.RNIFA)
minimum.M.RNIFA <-min(Top100.5.$M.RNIFA)
Q25.M.RNIFA <-quantile(Top100.5.$M.RNIFA,.25)
Q75.M.RNIFA <-quantile(Top100.5.$M.RNIFA,.75)
interquartile.range.M.RNIFA <-quantile(Top100.5.$M.RNIFA,.75)-quantile(Top100.5.$M.RNIFA,.25)

rbind(mean.M.RNIFA, median.M.RNIFA,range.M.RNIFA,standard.deviation.M.RNIFA,variance.M.RNIFA,standard.error.M.RNIFA,
      skewness.M.RNIFA,kurtosis.M.RNIFA,minimum.M.RNIFA,Q25.M.RNIFA,Q75.M.RNIFA,interquartile.range.M.RNIFA)
#within
mean.W.RNIFA <- mean(Top100.5.$W.RNIFA)
median.W.RNIFA <- median(Top100.5.$W.RNIFA)
range.W.RNIFA <-range(Top100.5.$W.RNIFA)
standard.deviation.W.RNIFA <-sd(Top100.5.$W.RNIFA)
variance.W.RNIFA <-var(Top100.5.$W.RNIFA)
standard.error.W.RNIFA <- standard.error(Top100.5.$W.RNIFA)
skewness.W.RNIFA <-skewness(Top100.5.$W.RNIFA)
kurtosis.W.RNIFA <-kurtosis(Top100.5.$W.RNIFA)
minimum.W.RNIFA <-min(Top100.5.$W.RNIFA)
Q25.W.RNIFA <-quantile(Top100.5.$W.RNIFA,.25)
Q75.W.RNIFA <-quantile(Top100.5.$W.RNIFA,.75)
interquartile.range.W.RNIFA <-quantile(Top100.5.$W.RNIFA,.75)-quantile(Top100.5.$W.RNIFA,.25)

rbind(mean.W.RNIFA, median.W.RNIFA,range.W.RNIFA,standard.deviation.W.RNIFA,variance.W.RNIFA,standard.error.W.RNIFA,
      skewness.W.RNIFA,kurtosis.W.RNIFA,minimum.W.RNIFA,Q25.W.RNIFA,Q75.W.RNIFA,interquartile.range.W.RNIFA)

#Independent variable
#Between
mean.M.RFD <- mean(Top100.5.$M.RFD)
median.M.RFD <- median(Top100.5.$M.RFD)
range.M.RFD <-range(Top100.5.$M.RFD)
standard.deviation.M.RFD <-sd(Top100.5.$M.RFD)
variance.M.RFD <-var(Top100.5.$M.RFD)
standard.error.M.RFD <- standard.error(Top100.5.$M.RFD)
skewness.M.RFD <-skewness(Top100.5.$M.RFD)
kurtosis.M.RFD <-kurtosis(Top100.5.$M.RFD)
minimum.M.RFD <-min(Top100.5.$M.RFD)
Q25.M.RFD <-quantile(Top100.5.$M.RFD,.25)
Q75.M.RFD <-quantile(Top100.5.$M.RFD,.75)
interquartile.range.M.RFD <-quantile(Top100.5.$M.RFD,.75)-quantile(Top100.5.$M.RFD,.25)

rbind(mean.M.RFD, median.M.RFD,range.M.RFD,standard.deviation.M.RFD,variance.M.RFD,standard.error.M.RFD,
      skewness.M.RFD,kurtosis.M.RFD,minimum.M.RFD,Q25.M.RFD,Q75.M.RFD,interquartile.range.M.RFD)
#Within
mean.W.RFD <- mean(Top100.5.$W.RFD)
median.W.RFD <- median(Top100.5.$W.RFD)
range.W.RFD <-range(Top100.5.$W.RFD)
standard.deviation.W.RFD <-sd(Top100.5.$W.RFD)
variance.W.RFD <-var(Top100.5.$W.RFD)
standard.error.W.RFD <- standard.error(Top100.5.$W.RFD)
skewness.W.RFD <-skewness(Top100.5.$W.RFD)
kurtosis.W.RFD <-kurtosis(Top100.5.$W.RFD)
minimum.W.RFD <-min(Top100.5.$W.RFD)
Q25.W.RFD <-quantile(Top100.5.$W.RFD,.25)
Q75.W.RFD <-quantile(Top100.5.$W.RFD,.75)
interquartile.range.W.RFD <-quantile(Top100.5.$W.RFD,.75)-quantile(Top100.5.$W.RFD,.25)

rbind(mean.W.RFD, median.W.RFD,range.W.RNIFA,standard.deviation.W.RFD,variance.W.RFD,standard.error.W.RFD,
      skewness.W.RFD,kurtosis.W.RFD,minimum.W.RFD,Q25.W.RNIFA,Q75.W.RFD,interquartile.range.W.RFD)

```



#### 8. Plot the boxplot of within transformed dependent variable and the key explanatory variable by a few individual (all of them if N around 50) and only the first 20 of them for larger data set. Comment on their differences of standard errors and means for each individuals

```{r}
Sample20 <- Top100.5.[which(Top100$Company == "ACCOR" |Top100$Company == "AIRBUS OPERATIONS" |Top100$Company == "ALICORNE" |Top100$Company == "AMADEUS" |
                           Top100$Company == "ARIANEGROUP SAS" |Top100$Company == "ASSA ABLOY FRANCE SAS" |Top100$Company == "AXA" |
                           Top100$Company == "BARILLA FRANCE" |Top100$Company == "BAYER" |Top100$Company == "	BEAUTE PRESTIGE 1" |
                           Top100$Company == "BEL" |Top100$Company == "BNP PARIBAS ASSET MANAGEMENT FRANCE" |Top100$Company == "BOUYGUES TELECOM" |
                           Top100$Company == "CARREFOUR HYPERMARCHES" |Top100$Company == "CARREFOUR SYSTEMES D'INFORMATION" |Top100$Company == "CDC HABITAT" |
                           Top100$Company == "CEGID" |Top100$Company == "CHAUSSON MATERIAUX" |Top100$Company == "CHRISTIAN DIOR COUTURE" |
                           Top100$Company == "	CIMENTS CALCIA"), ]

#Dependent 
boxplot(Sample20$W.RNIFA ~ Sample20$Company,main="Box Plot for Within Net Intangibles", ylab="Density", xlab="Sampe of first 20 companies")
#Independent
boxplot(Sample20$W.RFD ~ Sample20$Company,main="Box Plot for Within Financial Debt", ylab="Density", xlab="Sampe of first 20 companies")

```


#### 9. Compare and comment the within and between transformed bivariate correlation matrix for all variables (include a time trend 1,2,.,T). Check poor simple correlation with the dependent variables and high correlation between explanatory variables.



#### 10. Comment the bivariate auto-correlation and trend-correlations (check the number of observations).

\newpage

#### 11. Comment the bivariate graphs with linear, quadratic and Lowess fit for dependent and key explanatory variable (aid/gdp and growth of gdp): Within transformed, Between transformed.


\newpage


#### 12. Comment the results of estimations of Between, Within (fixed effects, (fe)) and Mundlak (random effects (re) including all X(i.) as regressors), two-way fixed effects (add year dummies in fe regression) and First differences, including all explanatory variables except the ones with high near-multicollinearity in their respective between or within space.

\newpage

#### 13. If one of your variable is time-invariant z(i) (Institutional quality ICRG for Burnside Dollar), run a baseline Hausman Taylor estimation including all X(i.) as instruments. Comment the results.

\newpage

#### 14. If one of your variable is time-invariant z(i) (Institutional quality ICRG for Burnside Dollar), run a between regression on z(i) explained by X(i.) and other time invariant variable (only with N observations). If the R2 is low, this may signal X(i.) are weak instruments poorly correlated with the variable z(i) to be instrumented. Comment.


\newpage

#### 15. Optional: mention or propose improvements to the Python, STATA, SAS or R code (copy it here). Optional: propose improvements, additional insights, and you do not know how to code them.

\newpage

## PART B (update results)

#### 1. Download 5 panel data variables from World Bank and/or IMF and/or FRED databases for the recent period (1990-2020) and for the largest coverage of emerging economies: GDP/head, GDP/head PPP-adjusted (very last update), Log(population), Foreign aid/GDP (ODA), of log an index of corruption (or good public sector governance) from the World Bank. From now on, consider as your sample only country-year observations which are available for ALL the 5 variables for at least TWO CONSECUTIVE years for a given country. The full class may coordinate for this updated database. In all the following questions except perhaps the last one, the PPP adjusted GDP is not used. So we consider 4 variables excluding GDP/head PPP adjusted.

```{r}
# Import Data 
# Inside the Data folder, get all the .RDS files except MSA_Large
panel_data <- list.files(path =  'Data/', pattern="*[^(MSA_Large)].RDS") %>% 
  map(., ~read_rds(paste0('Data/', .))) %>% 
  reduce(inner_join, by = c('iso2c', 'country', 'year'))

panel_data
```


```{r}
panel_data %>% 
  count(year)
```
We don't have any observations for the Year 1997, 1999 and 2001. Thus, we will restrict ourselves to the time period between 2002 to 2019 for 88 countries. 

```{r}
panel_data <- panel_data %>%
  filter(!year %in% c(1996, 1998, 2000))

panel_data %>% 
  count(country)
```

```{r}
# We remove them because they have negative ODA for at least one year
# We would need to find Gross ODA in order to have only positives values
country_to_remove <- panel_data %>% 
  group_by(country) %>% 
  filter(oda_net < 0) %>% 
  distinct(country) %>% 
  pull()

country_to_remove
```

```{r}
panel_data <- panel_data %>% 
  filter(!country %in% country_to_remove)

panel_data %>% 
  count(country)
```

\newpage

#### 2. Compute 2 growth rates using the difference of log: the growth of GDP/head (difference of log, denoted GDPg), the growth of foreign aid ODAg (but NOT the growth for foreign aid/GDP: remove the difference of log of GDP from the difference of log of foreign aid/GDP).



```{r}
panel_data <- panel_data %>% 
  arrange(country, year) %>% 
  group_by(country) %>% 
  mutate(g_gdp_per_cap = log(gdp_per_cap) - dplyr::lag(log(gdp_per_cap)),
         g_population = log(population) - dplyr::lag(log(population)),
         g_oda_net = log(oda_net) - dplyr::lag(log(oda_net))) %>% 
  ungroup()
```


\newpage

#### 3. Compute the between average over time for the first period and for the second period for the 6 variables. Provide the top 10 of countries for ODA/GDP with average over time for each period.

```{r}
panel_data %>% 
  group_by(country) %>% 
  mutate(oda_net_gdp_cap = oda_net / gdp_per_cap) %>% 
  # Summarise is used  to transform our dataframe and calculate the mean for each country
  summarise(across(where(is.double), ~mean(., na.rm = T))) %>% # across apply a function (here the mean) given a condition (is.double)
  arrange(desc(oda_net_gdp_cap)) %>% 
  relocate(country, oda_net_gdp_cap) %>% 
  slice_max(oda_net_gdp_cap, n = 10)
```

\newpage

#### 4. Compute the proportion of country-years observations in your database such that 0\<=ODA/GDP\<0.5%

```{r}
panel_data %>% 
  group_by(country) %>% 
  mutate(oda_net_gdp_cap = oda_net / gdp_per_cap) %>% 
  filter(oda_net_gdp_cap >= 0,
         oda_net_gdp_cap < 0.05) %>% 
  count(country) %>% 
  mutate(prop = round(n / 18, 2)) %>% 
  arrange(desc(n))
```

\newpage

#### 5. Compute the between and within transformations of the 6 variables over the full period. Provide the 4 histograms for ODA/GPD, growth of ODA, growth of GDP/head, corruption index for both between and within transformed variables (hence 8 histograms). Comment.


```{r}
# Between transformation
between_transformation <- panel_data %>% 
  group_by(country) %>% 
  mutate(oda_net_gdp_cap = oda_net / gdp_per_cap) %>% 
  summarise(across(where(is.double), mean, na.rm = T))
```


```{r}
fatal_fe_mod <- plm(corruption ~ gdp_per_cap, 
                    data = panel_data,
                    index = c("iso2c", "year"), 
                    model = "between")

summary(fatal_fe_mod)
```

```{r}
between_transformation %>% lm(corruption ~ gdp_per_cap, data = .)
```


```{r}
between_transformation %>% 
  select(country, oda_net_gdp_cap, g_oda_net, g_gdp_per_cap, corruption) %>% 
  pivot_longer(-country) %>% 
  ggplot(aes(x = value)) +
  geom_histogram() +
  facet_wrap(~name, scales = 'free')
```


```{r}
# Pas sur pour celui la
# Within transformation
panel_data %>% 
  group_by(country) %>% 
  mutate(oda_net_gdp_cap = oda_net / gdp_per_cap) %>% 
  mutate(across(where(is.double),~ . -  mean(., na.rm = T))) %>% 
  select(country, oda_net_gdp_cap, g_oda_net, g_gdp_per_cap, corruption) %>% 
  pivot_longer(-country) %>% 
  ggplot(aes(x = value)) +
  geom_histogram() +
  facet_wrap(~name, scales = 'free')
```


\newpage

#### 6. Provide the 3 bivariate graphs (with acronyms for observations NIC12, for Nicaragua 2012) for between and within (hence 6 graphs) of growth of GDP/head (vertical axis) with (1) ODA/GDP, (2) the growth of ODA; of corruption index with ODA/GDP. Comment.


```{r}
between_transformation %>% 
  pivot_longer(-c(country, g_gdp_per_cap)) %>% 
  filter(name %in% c('g_oda_net', 'oda_net_gdp_cap')) %>% 
  ggplot(aes(x = value, y = g_gdp_per_cap, label = country)) + 
  geom_point() + 
  facet_wrap(~name, scales = 'free') + 
   geom_text_repel(size = 2.5) +
  labs(title = 'Between Transformation', 
       x = '',
       y = 'Growth of GDP per capita (constant 2015$)')
```

```{r}
between_transformation %>% 
  ggplot(aes(x = oda_net_gdp_cap, y = corruption, label = country)) + 
  geom_point() +
  geom_text_repel(size = 2.5) +
  labs(title = 'Between Transformation', 
       x = 'Net ODA / GDP  (per capita)',
       y = 'Corruption')
```


```{r}
within_bivariate <- panel_data %>% 
  group_by(country) %>% 
  mutate(oda_net_gdp_cap = oda_net / gdp_per_cap) %>% 
  mutate(across(where(is.double),~ . -  mean(., na.rm = T)),
         # '..$' : Regex pour sélectionner les deux (un point = n'importe quelle terme)
         # derniers ($) charactères du vecteur Year
         # '^..' : ^ pour selectionner les deux premiers charactères
         # '..$' : $ pour selectionner les deux derniers charactères
         iso_year = paste0(iso2c, str_extract_all(year, '..$'))) %>% 
  ungroup() %>% 
  select(iso_year, country, year, gdp_per_cap, oda_net_gdp_cap, g_oda_net, g_gdp_per_cap, corruption) 
```


```{r}
fatal_btw_mod <- plm(corruption ~ gdp_per_cap, 
                    data = within_bivariate,
                    index = c("country", "year"), 
                    model = "within")

summary(fatal_btw_mod)
```

```{r}
within_bivariate %>% lm(corruption ~ gdp_per_cap, data = .)
```






```{r}
plot_biv <- function(data, x, y) {
  
  data %>% 
    ggplot(aes(x = {{ x }}, y = {{ y }}, label = iso_year)) +
    geom_point(size = 1, alpha = 0.5) +
    geom_text_repel(size=2) + 
    geom_smooth(method = lm, se = FALSE, color = 'blue', size = 0.7) +
    geom_smooth(method = loess, se = FALSE, color = 'red', size = 0.7) +
    geom_smooth(method = lm, formula = y ~ splines::bs(x, 3), se = FALSE, color = 'orange', size = 0.7)
  
}
```


```{r}
within_bivariate %>% 
  plot_biv(x = oda_net_gdp_cap, y = g_gdp_per_cap)
```

```{r}
within_bivariate %>% 
  plot_biv(x = g_oda_net, y = g_gdp_per_cap)
```

```{r}
within_bivariate %>% 
  plot_biv(x = oda_net_gdp_cap, y = corruption)
```

\newpage

#### 7. Comment the between versus within correlation matrix for the 6 variables in this order

```{r}
between_transformation %>% 
  select(c(g_oda_net, g_gdp_per_cap, gdp_per_cap, oda_net_gdp_cap, corruption, population)) %>% 
  #cor()%>% 
datasummary_correlation(title = 'Correlation matrix') %>%
kable_styling(latex_options = c("striped", "hold_position")) 
```

\newpage

#### 8. Run a one-way fixed effect foreign aid regression on ODA/GDP function of Ln(Population) and Ln(GDP/head). Comment.

\newpage

#### 9. Run a one-way fixed effect of Corruption Index function of Ln(GDP/head), of ODA/GDP and the growth of ODA. Comment.

\newpage

#### 10. Run a one-way fixed effect with the growth of GDP/head function of Ln(GDP/head), ODA/GDP, the growth of ODA and the Corruption index.

\newpage

#### 11. Propose an additional interesting estimation using this database.

\newpage

#### 12. Compute the between and within transformations of the 11 variables over the full period. Provide histograms for ODA/GPD, growth of ODA, growth of GDP/head for both between and within transformed. Comment.

```{r eval=FALSE, include=FALSE}
fe_model_plm <- plm(inv ~ capital, data = Grunfeld, 
                    index = c("firm", "year"), 
                    effect = "individual", model = "within")

summary(fe_model_plm)
```


```{r}
panel_data %>%
  ggplot(aes(x = year, y = gdp_ppp)) +
  geom_point() +
  geom_line(data = panel_data %>% group_by(year) %>% summarise(gdp_mean = mean(gdp_ppp)),
            aes(x = year, y = gdp_mean), col = "blue") +
  scale_x_continuous(labels = as.character(unique(panel_data$year)), 
                     breaks = unique(panel_data$year)) +
  labs(x = "Year", y = "GDP Per capita") +
  theme(axis.text.x = element_text(angle = 90))
```

