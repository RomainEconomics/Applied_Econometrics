---
author : "Khalil Janbek, Romain Jouhameau"
date: "01/01/2022"
output:
  pdf_document: 
  html_document:
    df_print: paged
editor_options: 
  markdown: 
    wrap: 72
    
header-includes:
  \usepackage[english]{babel}
  \usepackage[T1]{fontenc}
  \usepackage{tgbonum}
  \usepackage{multicol,multirow}
  \usepackage{calc}
  \usepackage{graphicx}
  \usepackage{rotating}
  \usepackage{tgtermes} 
  \usepackage{fancyhdr} 
  \usepackage{float} 
  \usepackage{xcolor} 
  \usepackage{geometry} 
  \usepackage{amsfonts} 
  \usepackage{booktabs}
  \usepackage{siunitx}
  \newcolumntype{d}{S[input-symbols = ()]}
  
  \geometry{left=0.8in,right=0.8in,top=1.0in,bottom=1.0in}
  \setlength{\parindent}{1.25em}
  \setlength{\parskip}{0.1em}
  
  \title{Applied Econometrics Homework \\ M2 FE }
---

```{=tex}
\pagestyle{fancy}
\fancyhf{}
\rhead{Khalil Janbek, Jouhameau Romain}
\lhead{Applied Econometrics Homework}
\rfoot{Page \thepage}
\maketitle
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                      message=FALSE, 
                      warning=FALSE,  
                      results = "hold",
                      out.width = '70%',
                      fig.align='center',
                      comment = "#>")
```

```{r}
library(data.table)
library(dtplyr)
library(dplyr, warn.conflicts = FALSE)
library(readxl)
library(janitor)
library(plm)
library(fixest)
library(modelsummary)
library(kableExtra)
library(ggrepel) # for spacing text inside plots
library(tidyverse)
library(sf)
library(usmap)
library(tsibble)
library(DBI) 
library(DataExplorer)
library(patchwork)
library(pander)
library(moments)
library(PerformanceAnalytics)
library(psych)  
```

```{r}
con <- dbConnect(RSQLite::SQLite(), "Data/DB.sqlite")
DB = tbl(con, "DB")

DB %>% 
  head() %>% 
  collect()
```



\newpage

## PART A:

#### Option 1 - Master thesis dataset

Khalil's Master thesis explores the topic of the performance of securitized mortgage loans in the US in the context of the coronavirus crisis. Based on issuance and performance data for more than 346,724 mortgage loans purchased by Freddie Mac in 2020Q1, combined with neighborhood-level coronavirus data, the thesis will examine, at the US local level, whether the coronavirus outbreak affected these loans' (i) delinquency status and (ii) prepayment. In parallel, the Master thesis also enquires whether the status of the lender that originated the loan - commercial bank or shadow bank, Fintech or not - has an influence on those two loan performance metrics. 

In those datasets, data are available at the geographical level of the Metropolitan Statistical Area (or MSA). MSAs are defined as "a core area containing a substantial population nucleus (50,000+ inhabitants), together with adjacent communities having a high degree of economic and social integration with that core". The US counts 384 MSA across the country. 

\newpage


#### 1. In your data set, which are the variables which are varying with respect to two indices (or more if you consider inflows and outflows from one individual or country to another individual or countries? Which are the variables which are varying only with respect to time? Which are the variables which are varying only with respect to individuals?


For each loan, the database records: 

- (i) time-invariant issuance metrics. Those variables vary only  with respect to individuals (in other words by loan) and do not vary over. Those time-invariant variables regroup for instance borrower credit score at issuance, the original loan to value, Original borrower debt-to-income and the lender type. 

- (ii) time-varying performance metrics. Those variables vary both with respect to time and with respect to individuals. For instance, prepayment (Zero Balance Code), Delinquency status, and unpaid principal. 



#### 2. What is the largest number of period T for individuals? What is the number of individuals?


The dataset counts 17 time periods, spanning from a month in 2020Q1 to June 2021. The sample consists of 346,724 loans, originated at various dates but purchased by Freddie Mac in 2020Q1. 

```{r}
DB %>% 
  count(Loan_Seq_Number) %>% 
  summarise(Number_Loans = n(),
            Max_T = max(n, na.rm = TRUE),
            Min_T = min(n, na.rm = TRUE),
            Mean_T = mean(n, na.rm = TRUE),
            Median_T = median(n, na.rm = TRUE),
            ) %>% 
  collect()
```

Lenders originating and selling these mortgage loans are classified as either commercial banks or shadow banks. The latter category also includes Fintech lenders. 

```{r}
DB %>%  
  mutate(Type = case_when(
           Lender_Type == 1 ~ 'Bank',
           Lender_Type == 0 & Fintech == 0 ~ 'Shadow Bank',
           Lender_Type == 0 & Fintech == 1 ~ 'Fintech'
         )) %>% 
  group_by(Type) %>% 
  count(Loan_Seq_Number) %>% 
  summarise(Number_Loans = n(),
                   Max_T = max(n, na.rm = TRUE),
                   Min_T = min(n, na.rm = TRUE),
                   Mean_T = mean(n, na.rm = TRUE),
                   Median_T = median(n, na.rm = TRUE)) %>% 
  collect()
```

\newpage



#### 3. Comment on the structure of the unbalanced panel (how many (and which) countries have a single observation, discontinuities between observations, how many have at least 2 consecutive observations (which is useful to compute lags, autocorrelations, first difference and within estimators)?

As shown in the previous question, our dataset has an unbalanced panel data structure, with time periods per individual loan varying from 1 to 17.



```{r}
DB %>%
  group_by(Loan_Seq_Number) %>%
  tally() %>% 
  count(n) %>%
  rename(Number_Periods_available = n,
         Number_of_loans = nn) %>% 
  mutate(cum = cumsum(Number_of_loans),
         percent = 100 * (cum / 346724))
```




```{r}
DB_temp <- DB %>% 
  # Reformatting the "Zero Balance Code" variable: 1 if prepaid, 0 otherwise
  mutate(Zero_Balance_Code = ifelse(Zero_Balance_Code == 1, 1, 0),
         Zero_Balance_Code = ifelse(is.na(Zero_Balance_Code) == T, 0, Zero_Balance_Code)) %>% 
  # Reformatting the "Delinquency status" variable: counting "REO acquisition as "NA"
  mutate(Delinquency_Status = ifelse(Delinquency_Status == 'RA', NA, Delinquency_Status),
         Delinquency_Status = ifelse(Delinquency_Status == '0', '0', '1')) %>% 
  # Reformatting the "Estimated Loan-to-Value" variable: counting "999" as "NA"
  mutate(E_LoanToValue = ifelse(E_LoanToValue == 999, NA, E_LoanToValue)) %>% 
  # Reformatting the "Original Debt-to-Income" variable: counting "999" as "NA"
  mutate(O_DebtToIncome = ifelse(O_DebtToIncome == 999, NA, O_DebtToIncome)) 

```


```{r}
DB_KJ <- DB_temp %>% 
  select(Loan_Seq_Number, Reporting_Period, Delinquency_Status, Zero_Balance_Code,
         confirmed, Credit_score, Current_Interest_Rate,Current_UPB, E_LoanToValue,
         O_DebtToIncome, O_LoanToValue, Time_to_Maturity, Lender_Type, Fintech, MSA, Seller_Name) %>% 
  mutate(Delinquency_Status = as.integer(Delinquency_Status)) %>% 
  collect() %>% 
  mutate_if(is.integer, as.double)
```


```{r}
Loans_by_MSA <- 
  DB_temp %>%                             
  group_by(MSA) %>%
  summarise(LoansPerMSA = n_distinct(Loan_Seq_Number)) %>% 
  collect() %>% 
  arrange(desc(LoansPerMSA))

Loans_by_MSA

# Identifying which loans are not related to an MSA (22,351 / 346,724)
#sum(Loans_by_MSA$LoansPerMSA)
```



\newpage

```{r}
full_dates <- DB %>%
  group_by(Loan_Seq_Number) %>%
  tally() %>% 
  filter(n == 17) %>% 
  pull(Loan_Seq_Number)

DB_test <- DB_KJ %>% 
  filter(Loan_Seq_Number %in% full_dates)
```





Starting by exploring missing observations, the graph shows that 6.75% of monthly loan performance observations relate to mortgage loans originated in locations that are not in an MSA - amounting to 22,351 loans, or 6.4% of the total of mortgages in our database. Those loans are likely to have been originated in sparsely populated areas.  

Monthly developments in COVID-19 confirmed cases by MSA are also missing in 8.45% of our monthly loan performance observations. This percentage includes the 6.75% of loan performance observations that are not located in an MSA. As our loan performance data start in February 2020, the remaining missing COVID-19 observations are related to monthly loan performance data that date prior to March 2020 - date at which COVID-19 cases started to be tracked. 


As briefly shown in question 2, we have between 1 and 17 consecutive observation for each loan contract. Nonetheless, the number of loans for which we have only 1 period of observation is very small compared to the total number of loans of the dataset - 123 out 346,724, or 0.3%. All the other loans therefore have at least 2 consecutive observations.


None of our loan performance data display discontinuities between observations.   

#### 4. Compute between transformed and within transformed variables for all variables. Present a table with the within, between and pooled variance for each variable. Compute the share of between and within variance in the total variance for each variable. Comment these results.

The pooled, within and between variance is defined as below: 

- Pooled deviation = $x_{i,t} - \overline{x}$
- Within deviation = $x_{i, t} - \overline{x}_i$
- Between deviation = $\overline{x}_{i} - \overline{x}$

```{r}
pooled <- DB_test %>% 
  mutate_at(vars(Delinquency_Status:Fintech), ~ . -  mean(., na.rm = T)) %>% 
  summarise(across(c(Delinquency_Status:Fintech), ~var(., na.rm = T))) %>% 
  pivot_longer(c(Delinquency_Status:Fintech), names_to = 'variable', values_to = 'Pooled')
```

```{r}
# Within transformation
within_transformation <- DB_test %>% 
  group_by(Loan_Seq_Number) %>% 
  mutate_at(vars(Delinquency_Status:Fintech), ~ . -  mean(., na.rm = T)) %>% 
  ungroup() %>% 
  summarise(across(c(Delinquency_Status:Fintech), ~var(., na.rm = T))) %>% 
  pivot_longer(c(Delinquency_Status:Fintech), names_to = 'variable', values_to = 'Within')
```

```{r}
between_transformation <- DB_test %>% 
  group_by(Loan_Seq_Number) %>% 
  mutate_at(vars(Delinquency_Status:Fintech), ~  mean(., na.rm = T)) %>% 
  ungroup() %>% 
  summarise(across(c(Delinquency_Status:Fintech), ~var(., na.rm = T))) %>% 
  pivot_longer(c(Delinquency_Status:Fintech), names_to = 'variable', values_to = 'Between')
```

The below table decomposes the total (pooled) deviation into a Within and Between part.  

```{r}
pooled %>% 
  left_join(within_transformation, by = 'variable') %>% 
  left_join(between_transformation, by = 'variable') %>% 
  kable() %>%
kable_styling(latex_options = c("striped", "hold_position"))
```

We can firstly single out the variances of the variables "Confirmed" (which captures the confirmed COVID-19 cases by MSA) and Current_UPB", as they have a significantly greater magnitude. On the other extreme of the spectrum, variables such as the "Delinquency status", the "Zero Balance Code" display among the lowest variances. Those variables have both non-zero within and between variance. 

On the other hand, the variables "Credit Score", "Current Interest Rate", "Original Debt to Income" and "Original Loan to Value", "Lender type" and "Fintech" do not vary over time, as they are characteristics defined at the origination of the loan. The therefore have no Within variance. 

Confirmed COVID cases therefore supply most of the variance, followed by the current UPB, time to maturity and credit score. 


\newpage


#### 5. Plot the distribution of the within and between transformed dependent variable and of you key (preferred) explanatory variable (not all the explanatory variable) [in Burnside and Dollar: GDP growth and foreign aid EDA/GDP], using on the same graph an histogram, a normal law with same empirical mean and standard error and a kernel continuous approximation. Comment the between and within difference for each variable, and compare within/within for dependent and explanatory variable, and between/between for dependent and explanatory variable: kurtosis, skewness, non-normality, high leverage observation (far from the mean), several modes (mixture of distribution)?


We carried out the calculation of within and between transformations for all variables except the binary variables - namely the lender type - as it would not deliver any useful information. We therefore plot the distribution of the Within and Between transformed variables for the "Delinquency status" dependent variable - which is a categorical variable - and one chosen explanatory variable, "Confirmed COVID cases" - which is continuous.

We chose to plot them on separate charts for better visual representation, to facilitate comparison.  

```{r}
within_transformation_graph <- DB_test %>% 
  group_by(Loan_Seq_Number) %>% 
  mutate_at(vars(Delinquency_Status:Fintech), ~ . -  mean(., na.rm = T)) %>% 
  ungroup() 

between_transformation_graph <- DB_test %>% 
  group_by(Loan_Seq_Number) %>% 
  summarise_at(vars(Delinquency_Status:Fintech), ~  mean(., na.rm = T)) %>% 
  ungroup() 
```


```{r include=FALSE}
within_between_plot <- function(col, adjust = 1) {
  # col is the name of the variable we're interested in
  # adjust is used to smooth the kernel curve (the black one)
  
  within_data <- within_transformation_graph %>% 
  select( {{ col }} ) %>% 
  drop_na() 
  
  between_data <- between_transformation_graph %>% 
  select( {{ col }} ) %>% 
  drop_na()
  
  # Get the name of the variable for the title plot
  col_name <- within_data %>% names()


within_plot <- ggplot(within_data, aes( {{ col }} )) +      
  # To compute the histogram 
  geom_histogram(aes(y = ..density..)) +
  # To compute the normal curve
  stat_function(fun = dnorm,
                args = list(mean = mean(within_data %>% pull()), # there's only 1 column
                            sd = sd(within_data %>% pull())), # pull is like within_data$col
                col = "#1b98e0",
                size = 1) +
  # To compute the kernel distribution
  geom_density(adjust = adjust)  + 
  labs(title = paste('Within transformation for ', col_name))

between_plot <- ggplot(between_data, aes( {{ col }} )) +        
  geom_histogram(aes(y = ..density..)) +
  stat_function(fun = dnorm,
                args = list(mean = mean(between_data %>% pull()),
                            sd = sd(between_data %>% pull())),
                col = "#1b98e0",
                size = 1) +
  geom_density(adjust = adjust)  + 
  labs(title = paste('Between transformation for ', col_name))

within_plot + between_plot
}
```

5.1. Between and Within transformation of the independent variable (confirmed COVID cases): 

```{r fig.height = 7, fig.width = 12}
within_between_plot(confirmed, adjust = 10) & theme_bw()
```

The most striking feature is the non-normality of the "Confirmed COVID cases" variable in the Between transformation case. A particularly striking point in the "Between" case is that the histogram and line are clearly skewed towards the right, owing to the presence of outliers (extremely large values at x = 30,000,000). We note that the greatest density is around x=0 in both the Within and Between cases. The striking point of the "Within" case is the leptokurtic normal distribution, with a relatively thicker right tail.   

5.2. Between and Within transformation of the dependent variable (Delinquency Status): 

```{r fig.height = 8, fig.width = 14}
within_between_plot(Delinquency_Status, adjust = 10)  & theme_bw()
```

The Within and Between histograms of the "Delinquency status" variable are notably more contrasted, owing to the categorical nature of this variable. Both charts are strongly centered around x=0. 
The Within transformed variable displays a normal and strongly leptokurtic distribution. The kernel tails, while flattening, are still visible, owing to the presence of outliers. Those outliers are clearly visible in the Between transformation case, which is skewed to the right.   

```{r include=FALSE}
Moments_stats <- function(data, col, title) {
  
  data %>% 
  select({{ col }}) %>% 
  summarise(skewness = skewness( {{ col }}, na.rm = T),
            kurtosis = kurtosis( {{ col }}, na.rm = T)) %>% 
    pivot_longer(skewness:kurtosis, names_to = ' ', values_to = title)
  }
```

```{r}
Moments_stats(within_transformation_graph, confirmed, 'Confirmed Within') %>% 
  left_join( Moments_stats(between_transformation_graph, confirmed, 'Confirmed Between'), by =' ') %>%
  left_join( Moments_stats(within_transformation_graph, Delinquency_Status, 'Delinquency_Status Within'), by =' ') %>%
  left_join( Moments_stats(between_transformation_graph, Delinquency_Status, 'Delinquency_Status Between'), by =' ') %>% 
  kable() %>%
kable_styling(latex_options = c("striped", "hold_position"))
```

We compare the above skewness and kurtosis coefficients to those of a Normal distribution, which are respectively of 0 and 3. 

While the skewness coefficients are somewhat close to those of a normal distribution for both within-transformed variable, it is not the case for the between-transformed variables, which are markedly above 0 - as expected visually. 

The Kurtosis coefficients confirm that the within and between distributions for both variables are strongly leptokurtic, especially in the case of the Delinquency status variable.  


#### 6. Plot boxplot of within distribution and between distribution for the dependent variable and the key explanatory variables. Comment that you find the same insights from question 5.

```{r}
boxplot_plot <- function(data, col, x_title) {
  
  data %>% 
  ggplot(aes(x = {{ col }} )) +
  geom_boxplot() +
  coord_flip() +
    labs(y = x_title, x = '') +
    theme_minimal()
  
}
```


```{r}
boxplot_plot(within_transformation_graph, confirmed, 'Confirmed within') +
  boxplot_plot(within_transformation_graph, Delinquency_Status, 'Delinquency_Status within') +
  boxplot_plot(between_transformation_graph, confirmed, 'Confirmed between') +
  boxplot_plot(between_transformation_graph, Delinquency_Status, 'Delinquency_Status between') +
  plot_layout(ncol = 4)
```
The result of the above boxplot confirms the intuitions derived from the graphs of question 5. 
Firstly, both variables - both in the within and between transformation case - are centered around 0. 
Secondly, in the Within-transformed case of both variables, we notice the low interquartile range, which matches their leptokurtic shapes in question 5. The above chart also confirms the presence of tails on both sides on the mean, with relatively more outliers above the mean in the case of the "Confirmed COVID cases" variable.
Finally, turning to the Between-transformed case, the above chart confirms the significantly greater interquartile range for the "Confirmed COVID cases" variable and the presence extreme outliers. It also confirms the very small dispersion of the Between-transformed "Delinquency status" variable. 


\newpage

#### 7. Compute univariate descriptive statistics (min, Q1, median, Q3, max, mean, standard error) for Within and Between transformed variables. Is the mean different from the median and why? How many standard errors from the mean are the min and max extremes (report (MAX-average)/standard error and (MIN-average)/standard error in the tables)?


```{r include=FALSE}
univ_stats <- function(data, col, title) {
  
  data %>% 
  select({{ col }}) %>% 
  summarise(mean = mean( {{ col }}, na.rm = T),
            median = median( {{ col }}, na.rm = T),
            std = sd( {{ col }}, na.rm = T),
            min = min( {{ col }}, na.rm = T),
            max = max( {{ col }}, na.rm = T),
            q25 = quantile( {{ col }}, probs = c(0.25), na.rm = T),
            q75 = quantile( {{ col }}, probs = c(0.75), na.rm = T)) %>% 
  pivot_longer(mean:q75, names_to = ' ', values_to = title)
  
}
```


```{r}
univ_stats(within_transformation_graph, confirmed, 'Confirmed Within') %>% 
  left_join( univ_stats(between_transformation_graph, confirmed, 'Confirmed Between'), by =' ') %>%
  left_join( univ_stats(within_transformation_graph, Delinquency_Status, 'Delinquency_Status Within'), by =' ') %>%
  left_join( univ_stats(between_transformation_graph, Delinquency_Status, 'Delinquency_Status Between'), by =' ') %>% 
  kable() %>%
kable_styling(latex_options = c("striped", "hold_position"))
```
The above table confirms the intuitions we derived from the charts and tables in question 5. 

We firstly notice a very significant difference between the mean and the median of the "Confirmed COVID cases" variables, both in the Within and Between transformed case. This result matches the large kurtosis of this distribution that we identified in question 5. In the "Within" case, while the distribution is centered around 0, we note that the median is negative: this result is in part driven by the presence of outliers that we highlighted in question 6.   

Secondly, turning to the variable "Delinquency status", the very high kurtosis that we identified in question 5 (of 19 and 25 for respectively the Within and the Between cases) is not reflected in the median (of 0.0). This statement is especially true in the "within" case. This is because the negative and positive outliers offset eachother, thereby resulting in a median of 0.    


\newpage

#### 8. Plot the boxplot of within transformed dependent variable and the key explanatory variable by a few individual (all of them if N around 50) and only the first 20 of them for larger data set. Comment on their differences of standard errors and means for each individuals

```{r}
random_20_indiv <- within_transformation_graph %>% 
  distinct(Loan_Seq_Number) %>% 
  slice_sample(n = 20) %>% 
  pull()

within_transformation_graph %>% 
  filter(Loan_Seq_Number %in% random_20_indiv) %>% 
  ggplot(aes(x = reorder(Loan_Seq_Number, Delinquency_Status), y = Delinquency_Status)) +
  geom_boxplot() +
  coord_flip()
```

This graphical representation unfortunately cannot provide useful insights for our dependent variable, as it is a categorical variable which takes on the value of 0 for most loans. 

Nonetheless, we can infer more conclusions from the dependent variables' charts. 

```{r}
random_20_indiv <- within_transformation_graph %>% 
  distinct(Loan_Seq_Number) %>% 
  slice_sample(n = 20) %>% 
  pull()

within_transformation_graph %>% 
  filter(Loan_Seq_Number %in% random_20_indiv) %>% 
  ggplot(aes(x = reorder(Loan_Seq_Number, E_LoanToValue), y = E_LoanToValue)) +
  geom_boxplot() +
  coord_flip()
```

The means are in overall centered around 0. Standard errors and interquartile ranges are very heterogeneous across different loans. 

```{r}
random_20_indiv <- within_transformation_graph %>% 
  distinct(Loan_Seq_Number) %>% 
  slice_sample(n = 20) %>% 
  pull()

within_transformation_graph %>% 
  filter(Loan_Seq_Number %in% random_20_indiv) %>% 
  ggplot(aes(x = reorder(Loan_Seq_Number, confirmed), y = confirmed)) +
  geom_boxplot() +
  coord_flip()
```

Means precisely centered around 0. Standard errors and interquartile ranges are very heterogeneous across loans. 

\newpage

#### 9. Compare and comment the within and between transformed bivariate correlation matrix for all variables (include a time trend 1,2,.,T). Check poor simple correlation with the dependent variables and high correlation between explanatory variables.

We exclude from the within variables bivariate correlation matrix the variables which are time-invariant (which therefore have 0 standard deviation). 

```{r}
within_transformation_graph %>% 
  mutate(Reporting_Period = as.numeric(as.factor(Reporting_Period)),
         MSA = as.factor(MSA),
         Seller_Name = as.factor(Seller_Name)) %>% 
  select(-Loan_Seq_Number, -Reporting_Period, - MSA, -O_DebtToIncome, -O_LoanToValue,-Lender_Type,-Fintech, -Credit_score) %>% 
datasummary_correlation(title = 'Correlation matrix within', fmt = 3) %>%
kable_styling(latex_options = c("striped", "hold_position")) %>%
row_spec(0, angle = 90)
```

As our dependent variable of interest is the "Delinquency status", we focus on the first column of this table. 

Those results are surprising: the number of confirmed cases, the estimated loan to value ratio and the loan's time to maturity are inversely related to the delinquency status. As increases in those variables indicate a degradation in the loans' credit quality, we would have expected those variables to be positively correlated with the delinquency status. 
Only interest rate has an expected positive sign - as a higher cost of debt can reasonably be associated with a more important loan delinquency.  


```{r}
between_transformation_graph %>% 
  select(-Loan_Seq_Number) %>% 
datasummary_correlation(title = 'Correlation matrix between', fmt = 3) %>%
kable_styling(latex_options = c("striped", "hold_position", "scale_down")) %>%
row_spec(0, angle = 90)
```

Thanks to the presence of variance in more explanatory variables, we can identify many more interesting relationships with the "Delinquency status" variable. 

Focusing again on the first column, the first striking point is that the correlation coefficients for nearly all variables take on an expected positive sign. Those above results indeed verify our working hypothesis that (i) confirmed COVID cases are positively related to the loan delinquency, similarly as (ii) interest rate, loan size, loan-to-value and debt-to-income. 
Nonetheless, it remains surprising that the "Credit score" correlation coefficient is negative. Similarly, the positive coefficient for the "Lender type" variable is surprising, as it seems to indicate that the fact that the lender is a commercial bank is positively related to loan delinquency, compared to if it was a shadow bank. 

\newpage



#### 10. Comment the bivariate auto-correlation and trend-correlations (check the number of observations).

We now turn to exploring autocorrelation and trend-correlation of the within-transformed variable and pooled variables (as the between-transformed variable has no time dimension). 

Starting with autocorrelation, we compute the autocorrelation coefficients for the following variables: delinquency status, confirmed COVID cases, the current interest rate, the current unpaid principal balance and estimated loan to value. 

```{r}
# Correlation with past values using within transformation
within_transformation_graph %>% 
  mutate(Reporting_Period = as.numeric(as.factor(Reporting_Period)),
         MSA = as.factor(MSA),
         Seller_Name = as.factor(Seller_Name)) %>% 
  select(-Loan_Seq_Number, -MSA, -Seller_Name, - Credit_score, -Lender_Type, -Fintech,
         -O_DebtToIncome, -O_LoanToValue ) %>% 
  group_by(Reporting_Period) %>% 
  summarise(across(Delinquency_Status:Time_to_Maturity, ~mean(., na.rm = T))) %>% 
  summarise(across(Delinquency_Status:Time_to_Maturity, ~cor(., dplyr::lag(.), use = "complete.obs"))) %>% 
  pivot_longer(Delinquency_Status:Time_to_Maturity)
```

The striking feature of the above table is that the within-transformed variables display a strongly auto-regressive pattern, with the delinquency status variables displaying the lowest coefficient as expected. Those results come as expected: (i) confirmed COVID-19 cases display a gradual rise over time, (ii) the current interest rate exhibits little change over time, (iii) the current unpaid principal balance displays a gradual decrease over time. 

We verify, using the below code, the p_value significance of those autocorrelation coefficients. 

```{r}
# Within transformation autocorrelation - P-values
within_transformation_graph %>% 
  mutate(Reporting_Period = as.numeric(as.factor(Reporting_Period)),
         MSA = as.factor(MSA),
         Seller_Name = as.factor(Seller_Name)) %>% 
  select(-Loan_Seq_Number, -MSA, -Seller_Name, - Credit_score, -Lender_Type, -Fintech,
         -O_DebtToIncome, -O_LoanToValue ) %>% 
  group_by(Reporting_Period) %>% 
  summarise(across(Delinquency_Status:Time_to_Maturity, ~mean(., na.rm = T))) %>% 
  summarise(across(Delinquency_Status:Time_to_Maturity, ~corr.test(., dplyr::lag(.), use = "complete.obs")$p)) %>% 
  pivot_longer(Delinquency_Status:Time_to_Maturity)
```

The extremely small p-values reported in the above table shows the significance of the strong auto-regressive pattern that we identified for those variables. 

We now examine the time-trend of those within-transformed variable.  

```{r}
# Correlation with the trend
test <- within_transformation_graph %>% 
  mutate(Reporting_Period = as.numeric(as.factor(Reporting_Period)),
         MSA = as.factor(MSA),
         Seller_Name = as.factor(Seller_Name)) %>% 
  select(-Loan_Seq_Number, -MSA, -Seller_Name, - Credit_score, -Lender_Type, -Fintech,
         -O_DebtToIncome, -O_LoanToValue ) %>% 
  group_by(Reporting_Period) %>% 
  summarise(across(Delinquency_Status:Time_to_Maturity, ~mean(., na.rm = T))) %>% 
  cor(use = "complete.obs")

test[,1]
```
The above table suggests that the the within-transformed COVID confirmed cases, current loan interest rate, unpaid principal balance and estimated loan-to-value ratio display strong time trends.

######################### SEE IF WE CAN ADD P-VALUES FOR THOSE COEFFS #########################

\newpage

#### 11. Comment the bivariate graphs with linear, quadratic and Lowess fit for dependent and key explanatory variable (aid/gdp and growth of gdp): Within transformed, Between transformed.

```{r}
plot_biv <- function(data, x, y) {
  
  data %>% 
    ggplot(aes(x = {{ x }}, y = {{ y }})) +
    geom_point(size = 1, alpha = 0.1) +
    geom_smooth(method = lm, se = FALSE, color = 'blue', size = 0.7) +
    geom_smooth(method = loess, se = FALSE, color = 'red', size = 0.7) +
    geom_smooth(method = lm, formula = y ~ splines::bs(x, 3), se = FALSE, color = 'orange', size = 0.7)
  
}
```


```{r}
# Very slow ...
within_transformation_graph[c(1:100000),] %>% 
  filter(Current_UPB > -15000) %>% 
  drop_na(confirmed, Current_UPB) %>% 
  plot_biv(x = confirmed, y = Current_UPB)
```

```{r}
# Very slow ...
within_transformation_graph[c(1:100000),] %>% 
  drop_na(confirmed, Delinquency_Status) %>% 
  plot_biv(x = confirmed, y = Delinquency_Status)
```

The relationship between confirmed COVID cases and our dependent variable (namely the loans' "Delinquency status") can unfortunately not be correctly captured through a linear correlation setup. 

To estimate the strength of those relationship, we turn to a Linear Probability Model (LPM) framework. 

\newpage


#### 12. Comment the results of estimations of Between, Within (fixed effects, (fe)) and Mundlak (random effects (re) including all X(i.) as regressors), two-way fixed effects (add year dummies in fe regression) and First differences, including all explanatory variables except the ones with high near-multicollinearity in their respective between or within space.


12.1. Linear Probability Models (LPM) on between-transformed variables. 

We run a between Linear Probability Model (LPM) regression of the loans' delinquency status on (i) the COVID-19 confirmed cases, (ii) the borrower's estimate loan-to-value and (iii) the loan's current interest rate.  

```{r}
reg_between <- plm(Delinquency_Status ~ confirmed+E_LoanToValue+Current_Interest_Rate, 
                    data = DB_KJ,
                    index = c("Loan_Seq_Number", "Reporting_Period"), 
                    model = "between") 

summary(reg_between)
```
Although all the regressors are statistically significant, the extremely small size of the regressors suggests the weak power of those variables to account for variability in the Delinquency status variable. 
We suspect that this is due to the significant imbalance in the dependent variable's distribution, as we have only 127,000 observations of significant loan delinquency against more than 4,700,000 observations of non-delinquency. This explains the very low R-squared of this regression. 

As this homework exercise is an opportunity for us to explore this Freddie Mac loan performance dataset, we run a Linear Probability Model (LPM) with other variables, in order to answer a different question: "During the first periods of the COVID-19 crisis, did shadow banks, especially fintechs, serve riskier borrowers?"
Based on Wang (2020), we run the following regression: 

```{r}
reg_between_2 <- plm(Fintech ~ E_LoanToValue+Credit_score+E_LoanToValue*Credit_score+Current_Interest_Rate, 
                    data = DB_KJ,
                    index = c("Loan_Seq_Number", "Reporting_Period"), 
                    model = "between") 

summary(reg_between_2)
```

As in Wang (2020), the R-squared is very low. Consistently with the intuition from the literature and to Wang (2020), the lower the credit score at origination, the more likely the loan is to have been originated by a Fintech lender. The above coefficients can be interpreted the following way: a 1 unit decrease in borrower's FICO score raises the probability of the loan being originated by a Fintech of 0.084%. Turning to the interpretation of the loan-to-value ratio coefficient: a 1% decrease in the borrower LTV ratio raises the probability that the loan was originated by a Fintech lender. 
Those results suggest that Fintech lenders, while targeting borrowers with lower credit scores, might compensate the risk by requiring a lower LTV ratio (in other words, higher collateral). 


12.2. Linear Probability Models (LPM) on within-transformed variables.


####################### SHALL WE KEEP THE BELOW CHUNK? ##########################

```{r}
# Some FE model au piff
# les FE sont apres le |
res_fe = feols(Delinquency_Status ~  Current_Interest_Rate | Loan_Seq_Number , 
               DB_KJ, panel.id = ~Loan_Seq_Number+Reporting_Period)

res_hfe = feols(Delinquency_Status ~  Current_Interest_Rate | Loan_Seq_Number + Reporting_Period, 
                DB_KJ, panel.id = ~Loan_Seq_Number+Reporting_Period)

res_Hfe = feols(Delinquency_Status ~  Current_Interest_Rate | Loan_Seq_Number + Reporting_Period + MSA, 
                DB_KJ, panel.id = ~Loan_Seq_Number+Reporting_Period)

res_HFE = feols(Delinquency_Status ~  Current_Interest_Rate | Loan_Seq_Number + Reporting_Period + MSA + Seller_Name, 
                DB_KJ, panel.id = ~Loan_Seq_Number+Reporting_Period)

etable(res_fe, res_hfe, res_Hfe, res_HFE, cluster = c('Loan_Seq_Number', 'Reporting_Period'))
       #postprocess.df = pandoc.table.return, style = 'rmarkdown')

#modelsummary(list(res_fe, res_hfe), gof_omit = "Pseudo|IC|Log")
```






For the coming regressions, we will focus on the first relationship, on the drivers of mortgage loan delinquency, as unfortunately, running the Linear Probability Models for predicting the probability of Fintech lending on the different variables transformations is computationally very heavy.   


We now run within fixed effects, random fixed effects and first-difference estimations, starting by our first relationship of interest, between COVID cases at the MSA level and loan delinquency status. 

```{r}
#Loan delinquency and local COVID cases: Fixed Effects (within) and Random Effects (random)
plmwithin <- plm(Delinquency_Status~confirmed+E_LoanToValue, 
                 data = DB_KJ, model = "within")

plmrandom <- plm(Delinquency_Status~confirmed+E_LoanToValue,  
                 data = DB_KJ, model = "random")

plmfd <- plm(Delinquency_Status~confirmed+E_LoanToValue,  
                 data = DB_KJ, model = "fd")
```

The fixed effect estimation controls for MSA-level characteristics thanks to the inclusion of MSA fixed effects. While the MSA fixed effects avoid the risk of omitted variable bias - as it controls for time-invariant factors that vary across MSA.

```{r}
summary(plmwithin)
```

12.3. Random effect estimation

```{r}
summary(plmrandom)
```
12.4. First difference estimation

```{r}
summary(plmfd)
```

One conclusion can be drawn of the above results: while the variable of confirmed COVID cases and for the estimated loan-to-value are significant at the 1% level, the R-squared and the correlation coefficients are extremely low.  
Those results corroborate the findings of the between estimation: those two variables therefore do not seem to capture much variability in the Delinquency status data, due to the strong imbalance between delinquent and non-delinquent loans.   

Finally, to check the existence of individual fixed effects, we run a Hausman test, comparing the results of the Between and Within Estimators.


12.5. Hausman endogeneity test

```{r}
kable(tidy(phtest(plmrandom, plmwithin)), caption=
 "Hausman endogeneity test for the random effects wage model")
```

The above output shows a low  p -value of the test, which indicates that the null hypothesis - stating that the individual random effects are exogenous - is rejected. The random effects estimation is therefore inconsistent. The fixed effects model is therefore the correct specification.


\newpage

#### 13. If one of your variable is time-invariant z(i) (Institutional quality ICRG for Burnside Dollar), run a baseline Hausman Taylor estimation including all X(i.) as instruments. Comment the results.

The effect of any time-invariant variable (such as the credit score) is eliminated through the "de-meaning transformation" of the variables. We therefore need to find a way to estimate the coefficients of "Confirmed" and "Estimated Loan-to-Value" without including fixed effects, while dealing with correlations with the error term, owing to ommitted variable bias. 
The Hausmann-Taylor approach will therefore be useful for this purpose: it allows us to account for panel data biases and still estimate our panel data coefficients - which cannot be done in a standard fixed effect approach. 

For conducting the Hausman-Taylor estimation, the R software does all the calculations for deciding which variable will be instrumented by a de-meaned instrumental variable and which variables will be employed in random effects.

The results are reported in the below table. 

```{r}
pht <- plm(Delinquency_Status ~ confirmed + E_LoanToValue + Credit_score + Current_Interest_Rate | confirmed + E_LoanToValue + Current_Interest_Rate,
          data=DB_KJ,model="random",random.method = "ht", inst.method = "baltagi")
summary(pht)

```

We now end up with theoretically unbiased estimations of those panel marginal effects. The results are quite comparable to the other specifications: all variables are significant to the 1% level. Nonetheless, the R-squared is extremely low. 

\newpage

#### 14. If one of your variable is time-invariant z(i) (Institutional quality ICRG for Burnside Dollar), run a between regression on z(i) explained by X(i.) and other time invariant variable (only with N observations). If the R2 is low, this may signal X(i.) are weak instruments poorly correlated with the variable z(i) to be instrumented. Comment.

To conclude, we verify the strength of our instruments by examining their correlation with our time-invariant variable "Credit score". 

```{r}
reg_between_Zi_Xi <- plm(Credit_score ~ E_LoanToValue+confirmed+Current_Interest_Rate, 
                    data = DB_KJ,
                    index = c("Loan_Seq_Number", "Reporting_Period"), 
                    model = "between") 

summary(reg_between_Zi_Xi)
```

Although each explanatory variable is significant at the 1% level, the reported R-squared is low (11%). Those results suggest the relative weakness of our the estimated Loan-to-Value ratio, the Confirmed COVID cases and Current interest rates variables for instrumenting the time-invariant variable Credit score. 


\newpage

#### 15. Optional: mention or propose improvements to the Python, STATA, SAS or R code (copy it here). Optional: propose improvements, additional insights, and you do not know how to code them.


\newpage

## PART B (update results)

#### 1. Download 5 panel data variables from World Bank and/or IMF and/or FRED databases for the recent period (1990-2020) and for the largest coverage of emerging economies: GDP/head, GDP/head PPP-adjusted (very last update), Log(population), Foreign aid/GDP (ODA), of log an index of corruption (or good public sector governance) from the World Bank. From now on, consider as your sample only country-year observations which are available for ALL the 5 variables for at least TWO CONSECUTIVE years for a given country. The full class may coordinate for this updated database. In all the following questions except perhaps the last one, the PPP adjusted GDP is not used. So we consider 4 variables excluding GDP/head PPP adjusted.

We download yearly data for 88 countries over 23 periods (between 1996 and 2019) for the following variables: (i) the World Bank corruption index, (ii) GDP per capita in euros, (iii) PPP-adjusted GDP per capita (iv) foreign aid - as % of Gross National Income and per capita - and (v) population.     

```{r}
# Import Data 
# Inside the Data folder, get all the .RDS files except MSA_Large
panel_data <- list.files(path =  'Data/', pattern="*[^(MSA_Large)].RDS") %>% 
  map(., ~read_rds(paste0('Data/', .))) %>% 
  reduce(inner_join, by = c('iso2c', 'country', 'year'))

panel_data
```

Based on the below table, as we lack observations for the years 1997, 1999 and 2001, we restrict our analysis to the 2002-2019 period for those 88 countries.  

```{r}
panel_data %>% 
  count(year)
```

We therefore remove the years 1996, 1998 and 2000 from our sample. 

```{r}
panel_data <- panel_data %>%
  filter(!year %in% c(1996, 1998, 2000))

panel_data %>% 
  count(country)
```

As we are concerned with the impact of foreign aid on economic growth, we also remove from our sample countries that have a negative net ODA. 

```{r}
# We remove them because they have negative ODA for at least one year
# We would need to find Gross ODA in order to have only positives values
country_to_remove <- panel_data %>% 
  group_by(country) %>% 
  filter(oda_net < 0) %>% 
  distinct(country) %>% 
  pull()

country_to_remove
```

We therefore arrive to the following final dataset, which comprises 77 countries over 18 years (2002-2019). 

```{r}
panel_data <- panel_data %>% 
  filter(!country %in% country_to_remove)

panel_data %>% 
  count(country)
```

\newpage

#### 2. Compute 2 growth rates using the difference of log: the growth of GDP/head (difference of log, denoted GDPg), the growth of foreign aid ODAg (but NOT the growth for foreign aid/GDP: remove the difference of log of GDP from the difference of log of foreign aid/GDP).


```{r}
panel_data <- panel_data %>% 
  arrange(country, year) %>% 
  group_by(country) %>% 
  mutate(g_gdp_per_cap = log(gdp_per_cap) - dplyr::lag(log(gdp_per_cap)),
         g_population = log(population) - dplyr::lag(log(population)),
         g_oda_net = log(oda_net) - dplyr::lag(log(oda_net))) %>% 
  ungroup()
```


\newpage

#### 3. Compute the between average over time for the first period and for the second period for the 6 variables. Provide the top 10 of countries for ODA/GDP with average over time for each period.

We separate our dataset in two periods of approximately equal size in terms of available observations: 2002-2013 for Period 1 and 2014-2019 for Period 2.

As in Jia and Williamson (2018), we compare the countries that are the top recipients of foreign aid compared to GDP in those two subsets of the database.

```{r}
Period_1 <- subset(panel_data, year == 2002:2013)

Period_1 %>% 
  group_by(country) %>% 
  mutate(oda_net_gdp_cap = oda_net / gdp_per_cap) %>% 
  # Summarise is used  to transform our dataframe and calculate the mean for each country
  summarise(across(where(is.double), ~mean(., na.rm = T))) %>% # across() applies a function (here the mean) given a condition (is.double)
  arrange(desc(oda_net_gdp_cap)) %>% 
  relocate(country, oda_net_gdp_cap) %>% 
  slice_max(oda_net_gdp_cap, n = 10)
```

```{r}
Period_2 <- subset(panel_data, year == 2014:2019)

Period_2  %>% 
  group_by(country) %>% 
  mutate(oda_net_gdp_cap = oda_net / gdp_per_cap) %>% 
  # Summarise is used  to transform our dataframe and calculate the mean for each country
  summarise(across(where(is.double), ~mean(., na.rm = T))) %>% # across() applies a function (here the mean) given a condition (is.double)
  arrange(desc(oda_net_gdp_cap)) %>% 
  relocate(country, oda_net_gdp_cap) %>% 
  slice_max(oda_net_gdp_cap, n = 10)

```

We notice that the 10 countries with the highest ODA/GDP average over the period differ between those two samples. While Malawi, Rwanda, Sierra Leone, Niger and the Central African Republic are top recipients in foreign aid / GDP on average for both periods 1 and 2, Burkina Faso, Cabo Verde and Tanzania have a lower relative to period 1 and are no more among the top 10 recipients in period 2. 

Average ODA/GDP are higher in period 2 - ranging from 10.4% to 32% compared to 7.9% and 17% in period 1 - explained by the presence of other countries compared to period 1, namely the Gambia, Guinea-Bissau, the Solomon Islands, Burundi and Vanuatu. 

The magnitude of the change in the average  ODA/GDP ratio for the Central African republic is the most striking, from 17% in period 1 to 32% on average over the period 2.

\newpage

#### 4. Compute the proportion of country-years observations in your database such that 0\<=ODA/GDP\<0.5%

Now turning to the countries with the lowest ODA/GDP ratios, 23 countries of our dataset have ratios between 0% and 0.5%. Notably, Algeria, Brazil, Costa Rica, Dominican Republic, India, Mexico and Turkey have a ratio lower than 0.5% for all the 18 years of observations.

Albania, CÃ´te d'Ivoire, Iraq and Vietnam, while having among the lowest ODA/GDP ratios, have an ODA/GDP lower than 0.5% for only 1 year of observation.  

```{r}
panel_data %>% 
  group_by(country) %>% 
  mutate(oda_net_gdp_cap = oda_net / gdp_per_cap) %>% 
  filter(oda_net_gdp_cap >= 0,
         oda_net_gdp_cap < 0.005) %>% 
  count(country) %>% 
  mutate(prop = round(n / 18, 2)) %>% 
  arrange(desc(n))
```

\newpage

#### 5. Compute the between and within transformations of the 6 variables over the full period. Provide the 4 histograms for ODA/GPD, growth of ODA, growth of GDP/head, corruption index for both between and within transformed variables (hence 8 histograms). Comment.


```{r}
# Between transformation
between_transformation <- panel_data %>% 
  group_by(country) %>% 
  mutate(oda_net_gdp_cap = oda_net / gdp_per_cap) %>% 
  summarise(across(where(is.double), mean, na.rm = T))
```

The important message of the below charts in the non-normality of the 'Between-transformed' variables. While we have no numeric information regarding the parameters of those distributions, we notice that the Between-transformed 'corruption' variable displays a positive skewness - it has a relatively fatter right tail. The Between-transformed 'ODA / GDP per capita' rather has the shape of a gamma distribution. 


```{r}
between_transformation %>% 
  select(country, oda_net_gdp_cap, g_oda_net, g_gdp_per_cap, corruption) %>% 
  pivot_longer(-country) %>% 
  ggplot(aes(x = value)) +
  geom_histogram() +
  facet_wrap(~name, scales = 'free')
```

The most striking characteristic in the 'within-transformed' case is the apparent normality of the corruption variable and the 'ODA / GDP per capita' variable. Although those charts give no precisions about the kurtosis of those within-transformed variable, we can at least conclude that the distributions are leptokurtic and that those variables are evenly-distributed around the mean. 



```{r}
# Within transformation
panel_data %>% 
  group_by(country) %>% 
  mutate(oda_net_gdp_cap = oda_net / gdp_per_cap) %>% 
  mutate(across(where(is.double),~ . -  mean(., na.rm = T))) %>% 
  select(country, oda_net_gdp_cap, g_oda_net, g_gdp_per_cap, corruption) %>% 
  pivot_longer(-country) %>% 
  ggplot(aes(x = value)) +
  geom_histogram(bins = 50) +
  facet_wrap(~name, scales = 'free')

```


\newpage

#### 6. Provide the 3 bivariate graphs (with acronyms for observations NIC12, for Nicaragua 2012) for between and within (hence 6 graphs) of growth of GDP/head (vertical axis) with (1) ODA/GDP, (2) the growth of ODA; of corruption index with ODA/GDP. Comment.

We start by examining the bivariate graphs in the between transformation case. 

```{r}
between_transformation %>% 
  pivot_longer(-c(country, g_gdp_per_cap)) %>% 
  filter(name %in% c('g_oda_net', 'oda_net_gdp_cap')) %>% 
  ggplot(aes(x = value, y = g_gdp_per_cap, label = country)) + 
  geom_point() + 
  geom_smooth(method = "lm") +
  facet_wrap(~name, scales = 'free') + 
   geom_text_repel(size = 2.5) +
  labs(title = 'Between Transformation', 
       x = '',
       y = 'Growth of GDP per capita (constant 2015$)')
```

In the between case, a negative relationship between GDP per capita growth and (i) ODA/GDP and (ii) ODA/GDP growth seems to be captured by this linear model. Observations seems to be clustered around ODA/GDP = 0.05 and ODA/GDP growth a little above 0. We nonetheless need to examine whether to make sure whether the fitting of those 2 univariate models is not only due to noise, and therefore to examine the significance of the correlation coefficient between these two variables.  

```{r}
summary(between_transformation %>% lm(g_gdp_per_cap ~ -1 + g_oda_net, data = .))

```
```{r}
summary(between_transformation %>% lm(g_gdp_per_cap ~ -1 + oda_net_gdp_cap, data = .))

```

As per the above results, the correlation coefficient between GDP per capita and ODA/GDP is significant at the 1% level in both cases, which suggests that those two univariate models are not fitting to noise or outliers. 

We continue by examining the bivariate graph of the corruption index and ODA/GDP in the between transformation case. 

```{r}
between_transformation %>% 
  ggplot(aes(x = oda_net_gdp_cap, y = corruption, label = country)) + 
  geom_point() +
  geom_smooth(method = "lm") +
  geom_text_repel(size = 2.5) +
  labs(title = 'Between Transformation', 
       x = 'Net ODA / GDP  (per capita)',
       y = 'Corruption')
```

As opposed to the previous two cases, the bivariate linear specification does not manage to capture the variance of the corruption index. The regression line is close to y=0.  

```{r}
within_bivariate <- panel_data %>% 
  group_by(country) %>% 
  mutate(oda_net_gdp_cap = oda_net / gdp_per_cap) %>% 
  mutate(across(where(is.double),~ . -  mean(., na.rm = T)),
         # '..$' : Regex pour sÃ©lectionner les deux (un point = n'importe quelle terme)
         # derniers ($) charactÃ¨res du vecteur Year
         # '^..' : ^ pour selectionner les deux premiers charactÃ¨res
         # '..$' : $ pour selectionner les deux derniers charactÃ¨res
         country_year = paste0(country, '-', str_extract_all(year, '..$'))) %>% 
  ungroup() %>% 
  select(country_year, country, year, gdp_per_cap, oda_net_gdp_cap, g_oda_net, g_gdp_per_cap, corruption) 
```


```{r}
within_bivariate %>% lm(corruption ~ -1 + gdp_per_cap, data = .)
```


```{r}
plm(corruption ~ gdp_per_cap, 
                    data = panel_data,
                    index = c("country", "year"), 
                    model = "within") %>% 
  summary()
```


Turning now to the bivariate graphs of the within case:


```{r}
plot_biv <- function(data, x, y) {
  
  data %>% 
    ggplot(aes(x = {{ x }}, y = {{ y }}, label = country_year)) +
    geom_point(size = 1, alpha = 0.5) +
    geom_text_repel(size=2) + 
    geom_smooth(method = lm, se = FALSE, color = 'blue', size = 0.7) +
    geom_smooth(method = loess, se = FALSE, color = 'red', size = 0.7) +
    geom_smooth(method = lm, formula = y ~ splines::bs(x, 3), se = FALSE, color = 'orange', size = 0.7)
  
}
```


We start by plotting the within bivariate graph of the growth of GDP/capita with ODA/GDP. We add 3 specifications of regression lines to those clouds of data: a linear model (in blue), a quadratic specification (in orange) and a LOWESS specification (in red).   

```{r}
within_bivariate %>% 
  plot_biv(x = oda_net_gdp_cap, y = g_gdp_per_cap)
```
In this first case, the 3 specifications fail to capture the variance of the growth of GDP/capita, as the fiting lines are nearly horizontal. Observations are markedly clustered around ODA/GDP = 0, which suggests orthogonality (or put simply, uncorrelation) between those two variables in the within-transformed case.  

We then plot the within bivariate graph of the growth of GDP / capita with the growth rate of ODA.   

```{r}
within_bivariate %>% 
  plot_biv(x = g_oda_net, y = g_gdp_per_cap)
```

The same conclusion can be drawn for this bivariate relationship in the linear case, which seems to fail to capture the variance of GDP per capita growth. While the quadratic and LOWESS specifications seem to perform slightly better, this is driven by the presence of outliers. 

Finally, We plot the within bivariate graphs of the corruption index with ODA/GDP. Similarly to the previous case, the strong cluster around ODA/GDP = 0 signals the same orthogonality between those two variables, and the quadratic and LOWESS specifications seem to capture variance drivenby the outliers.   

```{r}
within_bivariate %>% 
  plot_biv(x = oda_net_gdp_cap, y = corruption)
```


\newpage

#### 7. Comment the between versus within correlation matrix for the 6 variables in this order

```{r}
between_transformation %>% 
  select(c(oda_net_gdp_cap, corruption, population, gdp_per_cap, g_gdp_per_cap, g_oda_net)) %>% 
  #cor()%>% 
datasummary_correlation(title = 'Correlation matrix') %>%
kable_styling(latex_options = c("striped", "hold_position")) 
```
From the first column of the above table, we notice that as expected, corruption, population, and GDP per capita are negatively related to the level of foreign aid/GDP. This intuitively makes sense: higher GDP/capita calls for a lower need for foreign aid and higher corruption levels deters foreign aid. The correlation coefficient sign for the log of population and foreign aid/GDP is less intuitive to interpret. 
We also notice the interesting strong and positive sign of the correlation coefficient between GDP per capita and the corruption index in the second column. 

We analyze the correlation matrix for the within case as well. We perform the two analyses separately: grouping the between and within transformed variables in one same correlation matrix would provide little information, as the between and within variables are orthogonal by essence.    

ADD THE WITHIN CORRELATION MATRIX HERE. 

COMMENT OF WITHIN CORR MATRIX: XXX


\newpage


#### 8. Run a one-way fixed effect foreign aid regression on ODA/GDP function of Ln(Population) and Ln(GDP/head). Comment.

```{r}
res_fe = feols(oda_gni ~  log(population) + log(gdp_per_cap) | country , 
               panel_data, panel.id = ~country+year)

res_hfe = feols(oda_gni ~  log(population) + log(gdp_per_cap) | country + year, 
                panel_data, panel.id = ~country+year)

#etable(res_fe, res_hfe, postprocess.df = pandoc.table.return, style = 'rmarkdown')
modelsummary(list(res_fe, res_hfe), gof_omit = "Pseudo|IC|Log")

```
The above regression confirms the results of the above Between-correlation matrix: the two variables "population" and "GDP per capita" are negatively correlation with the foreign aid variable. 
The addition of year fixed effects improves only very slightly the high R-squared and adjusted R-squared (by less than 1 percentage point). 

```{r}
summary(res_fe)
summary(res_hfe)

```
The coefficients are highly significant, at the 1% level for most. Those findings are therefore consistents with the results of the descriptive statistics. 


\newpage

#### 9. Run a one-way fixed effect of Corruption Index function of Ln(GDP/head), of ODA/GDP and the growth of ODA. Comment.

```{r}
res_fe_2 = feols(corruption ~  oda_gni + log(gdp_per_cap) + g_oda_net | country , 
               panel_data, panel.id = ~country+year)

res_hfe_2 = feols(corruption ~  oda_gni + log(gdp_per_cap) + g_oda_net | country + year, 
                panel_data, panel.id = ~country+year)

#etable(res_fe, res_hfe, postprocess.df = pandoc.table.return, style = 'rmarkdown')
modelsummary(list(res_fe_2, res_hfe_2), gof_omit = "Pseudo|IC|Log")
```

As we noted in the descriptive statistics part of question 7, GDP per capita is positively correlated with the corruption variable, with a coefficient relatively larger in magnitude compared to the other two coefficients. The two foreign aid variables (as % of GDP and % growth) make nearly no contribution to the variance of the corruption index: the foreign aid growth variable is in fact not significant (as per the below table). Those results are therefore very much in line with the findings of the bivariate correlation matrix in question 7. 

We finally note that the inclusion of year fixed effect in model 2 does not add explanatory power to the model.  

```{r}
summary(res_fe_2)
summary(res_hfe_2)

```

\newpage

#### 10. Run a one-way fixed effect with the growth of GDP/head function of Ln(GDP/head), ODA/GDP, the growth of ODA and the Corruption index.

```{r}
res_fe_3 = feols(g_gdp_per_cap ~  oda_gni + log(gdp_per_cap) + g_oda_net + corruption| country , 
               panel_data, panel.id = ~country+year)

res_hfe_3 = feols(g_gdp_per_cap ~  oda_gni + log(gdp_per_cap) + g_oda_net + corruption | country + year, 
                panel_data, panel.id = ~country+year)

#etable(res_fe, res_hfe, postprocess.df = pandoc.table.return, style = 'rmarkdown')
modelsummary(list(res_fe_3, res_hfe_3), gof_omit = "Pseudo|IC|Log")
```
The above regression results suggest no meaningful statistical relationship between GDP/capita growth and the Log(GDP/capita), foreign aid/GDP, foreign aid growth and the Corruption index: coefficients are of small magnitude, especially compared to standard errors, and the goodness-of-fit metrics (R-squared and Adjusted R-squared) are low. 

```{r}
summary(res_fe_3)
summary(res_hfe_3)

```

The above table further proves that none of the regressors is statistically significant, to the exception of the log(GDP per capita) in the country and year fixed effect regression, quite understandably. 

\newpage

#### 11. Propose an additional interesting estimation using this database.

\newpage

#### 12. Compute the between and within transformations of the 11 variables over the full period. Provide histograms for ODA/GPD, growth of ODA, growth of GDP/head for both between and within transformed. Comment.



